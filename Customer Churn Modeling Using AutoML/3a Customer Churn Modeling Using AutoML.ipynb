{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "****Important – Do not use in production, for demonstration purposes only – please review the legal notices before continuing****"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Churn Modeling Using AutoML\n",
        "\n",
        "Customer churn is the proportion of customers that stop utilizing your product or service. This notebook builds a predictive model for customer churn using Azure's AutoML in a retail scenario.\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Picture](https://stretailprod.blob.core.windows.net/notebookimages/customer_churn.jpg?sp=r&st=2022-02-24T21:05:18Z&se=2024-02-25T05:05:18Z&sv=2020-08-04&sr=b&sig=ijbMsd7bZ%2F0ia9z3RiUIATi3qN6qfxryQaYfh07DOII%3D)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Experiment, Workspace, Dataset, Datastore\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1659394339948
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from azure.storage.blob import ContainerClient, BlobClient\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "from copy import deepcopy\n",
        "import GlobalVariables as gv"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1659394340623
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link with Synapse Apache Spark Pool"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import LinkedService\n",
        "import datetime  \n",
        "from azureml.core import Workspace, LinkedService, SynapseWorkspaceLinkedServiceConfiguration\n",
        "\n",
        "# Azure Machine Learning workspace\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "linked_service = LinkedService.get(ws, 'synapselink1')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1659394344607
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing using synapse commands"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start the spark pool\n",
        "%synapse start -c aidemocompute001"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Starting session 'aml_notebook_295628', this may take several minutes ......................................................................................................................................................................................................................................................................................................................................... Succeeded!\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1659394549526
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Load datasets\n",
        "contact = spark.read.load('wasbs://customer-churn-data@stretailprod.blob.core.windows.net/contact.csv', format='csv', header=True).toPandas()\n",
        "online_purchases = spark.read.load('wasbs://customer-churn-data@stretailprod.blob.core.windows.net/onlinepurchases.csv', format='csv', header=True).toPandas()\n",
        "customer_loyalty = spark.read.load('wasbs://customer-churn-data@stretailprod.blob.core.windows.net/customerloyalty.csv', format='csv', header=True).toPandas()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1658782343932
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "contact.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "    ContactId FirstName  ...         Occupation CustomerSatisfaction\n0  CNTID_1000     Abbie  ...  Software Engineer                 high\n1  CNTID_1001   Kenneth  ...            Teacher                 high\n2  CNTID_1002   Anthony  ...            Teacher                 high\n3  CNTID_1003   Michael  ...            Teacher               medium\n4  CNTID_1004   Richard  ...            Teacher               medium\n\n[5 rows x 20 columns]\n"
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "contact.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5002 entries, 0 to 5001\nData columns (total 20 columns):\n #   Column                Non-Null Count  Dtype \n---  ------                --------------  ----- \n 0   ContactId             5002 non-null   object\n 1   FirstName             5002 non-null   object\n 2   LastName              5002 non-null   object\n 3   FullName              5002 non-null   object\n 4   DateOfBirth           5001 non-null   object\n 5   Gender                5002 non-null   object\n 6   EMail                 5002 non-null   object\n 7   Telephone             5002 non-null   object\n 8   PostCode              5002 non-null   object\n 9   StreetAddress         5002 non-null   object\n 10  City                  5002 non-null   object\n 11  State                 5002 non-null   object\n 12  Country               5002 non-null   object\n 13  CreatedOn             5002 non-null   object\n 14  Headshot              5002 non-null   object\n 15  Loyalty Tier          5002 non-null   object\n 16  Email Subscriber      5002 non-null   object\n 17  Income                5002 non-null   object\n 18  Occupation            5002 non-null   object\n 19  CustomerSatisfaction  5002 non-null   object\ndtypes: object(20)\nmemory usage: 781.7+ KB\n"
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Edit column types\n",
        "\n",
        "import pandas as pd\n",
        "contact['Income'] = pd.to_numeric(contact['Income'])\n",
        "contact['DateOfBirth'] = pd.to_datetime(contact['DateOfBirth'])\n",
        "contact['CreatedOn'] = pd.to_datetime(contact['CreatedOn'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1658782435090
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "online_purchases.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 12369 entries, 0 to 12368\nData columns (total 7 columns):\n #   Column               Non-Null Count  Dtype \n---  ------               --------------  ----- \n 0   ContactId            12369 non-null  object\n 1   PurchaseId           12369 non-null  object\n 2   ProductId            12369 non-null  object\n 3   PurchasedOn          12369 non-null  object\n 4   TotalPrice           12369 non-null  object\n 5   ActivityTypeDisplay  12369 non-null  object\n 6   Subject              12369 non-null  object\ndtypes: object(7)\nmemory usage: 676.6+ KB\n"
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Edit column types\n",
        "\n",
        "online_purchases['TotalPrice'] = pd.to_numeric(online_purchases['TotalPrice'])\n",
        "online_purchases['PurchasedOn'] = pd.to_datetime(online_purchases['PurchasedOn'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1658782344429
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "customer_loyalty.info()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5002 entries, 0 to 5001\nData columns (total 12 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   LoyaltyId     5002 non-null   object\n 1   ContactId     5002 non-null   object\n 2   FirstName     5002 non-null   object\n 3   LastName      5002 non-null   object\n 4   FullName      5002 non-null   object\n 5   DateOfBirth   5002 non-null   object\n 6   Gender        5002 non-null   object\n 7   EMail         5002 non-null   object\n 8   Telephone     5000 non-null   object\n 9   RewardPoints  5002 non-null   object\n 10  CreditCard    5002 non-null   object\n 11  CreatedOn     5002 non-null   object\ndtypes: object(12)\nmemory usage: 469.1+ KB\n"
        }
      ],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Edit column types\n",
        "\n",
        "customer_loyalty['RewardPoints'] = pd.to_numeric(customer_loyalty['RewardPoints'])\n",
        "customer_loyalty['CreatedOn'] = pd.to_datetime(customer_loyalty['CreatedOn'])\n",
        "customer_loyalty['DateOfBirth'] = pd.to_datetime(customer_loyalty['DateOfBirth'])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1658782344598
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Add RewardPoints column from customer_loyalty to contact dataframe\n",
        "\n",
        "contact['RewardPoints'] = customer_loyalty['RewardPoints']"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "gather": {
          "logged": 1658782344691
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Sum total purchases by a customer and get last purchased date\n",
        "\n",
        "temp = online_purchases.groupby(['ContactId'])[['TotalPrice']].sum()\n",
        "temp2 = online_purchases.groupby(['ContactId'])[['PurchasedOn']].max()\n",
        "temp_df = pd.merge(temp, temp2, on = \"ContactId\")\n",
        "temp_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                                      TotalPrice PurchasedOn\nContactId                                                   \n98e79d76-a45a-e911-a970-000d3a39c2c9          90  2017-08-08\nCNTID_1000                                  7846  2019-01-20\nCNTID_1003                                    47  2017-08-09\nCNTID_1004                                   209  2018-07-22\nCNTID_1006                                   311  2019-01-13\n...                                          ...         ...\nCNTID_5997                                    84  2018-08-22\nCNTID_5998                                   679  2019-01-25\nCNTID_5999                                   605  2018-07-31\nf1bf9a01-b056-e711-abaa-00155d701c02         484  2019-03-06\nf4444de5-664e-e911-a9ac-000d3a2d57c3         167  2018-08-07\n\n[4124 rows x 2 columns]\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1658782344777
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Calculate days since last purchase\n",
        "\n",
        "import datetime\n",
        "\n",
        "vdate = datetime.datetime(2019, 3, 6)\n",
        "\n",
        "temp_df['LastPurchased'] = [vdate-x for x in temp_df.PurchasedOn]\n",
        "\n",
        "# Drop column to avoid bias\n",
        "temp_df.drop('PurchasedOn', axis=1, inplace=True)\n",
        "temp_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                                      TotalPrice LastPurchased\nContactId                                                     \n98e79d76-a45a-e911-a970-000d3a39c2c9          90      575 days\nCNTID_1000                                  7846       45 days\nCNTID_1003                                    47      574 days\nCNTID_1004                                   209      227 days\nCNTID_1006                                   311       52 days\n...                                          ...           ...\nCNTID_5997                                    84      196 days\nCNTID_5998                                   679       40 days\nCNTID_5999                                   605      218 days\nf1bf9a01-b056-e711-abaa-00155d701c02         484        0 days\nf4444de5-664e-e911-a9ac-000d3a2d57c3         167      211 days\n\n[4124 rows x 2 columns]\n"
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1658782344864
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Calculate if a person has churned or not depending on how long it's been since they last purchased\n",
        "\n",
        "from datetime import timedelta\n",
        " \n",
        "#100 days\n",
        "td = timedelta(100)\n",
        "\n",
        "temp_df['Churned'] = [i >= td for i in temp_df.LastPurchased]\n",
        "\n",
        "# Drop column to avoid bias\n",
        "temp_df.drop('LastPurchased', axis=1, inplace=True)\n",
        "temp_df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                                      TotalPrice  Churned\nContactId                                                \n98e79d76-a45a-e911-a970-000d3a39c2c9          90     True\nCNTID_1000                                  7846    False\nCNTID_1003                                    47     True\nCNTID_1004                                   209     True\nCNTID_1006                                   311    False\n...                                          ...      ...\nCNTID_5997                                    84     True\nCNTID_5998                                   679    False\nCNTID_5999                                   605     True\nf1bf9a01-b056-e711-abaa-00155d701c02         484    False\nf4444de5-664e-e911-a9ac-000d3a2d57c3         167     True\n\n[4124 rows x 2 columns]\n"
        }
      ],
      "execution_count": 16,
      "metadata": {
        "gather": {
          "logged": 1658782344947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Join the tables together to make a unified dataset and remove unnecessary columns\n",
        "\n",
        "df = pd.merge(contact, temp_df, on=\"ContactId\")\n",
        "df.drop(['FirstName', 'LastName', 'FullName', 'EMail', 'Telephone', 'StreetAddress', 'Headshot', 'City', 'PostCode'], axis=1, inplace=True)\n",
        "df"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "                                 ContactId DateOfBirth  ... TotalPrice Churned\n0                               CNTID_1000  1986-05-08  ...       7846   False\n1                               CNTID_1003  2006-09-03  ...         47    True\n2                               CNTID_1004  1997-07-30  ...        209    True\n3     f4444de5-664e-e911-a9ac-000d3a2d57c3  1989-03-08  ...        167    True\n4                               CNTID_1006  2016-09-20  ...        311   False\n...                                    ...         ...  ...        ...     ...\n4118                            CNTID_5996  1983-07-06  ...        634   False\n4119                            CNTID_5997  1981-04-20  ...         84    True\n4120                            CNTID_5998  1970-12-25  ...        679   False\n4121                            CNTID_5999  2014-12-04  ...        605    True\n4122  f1bf9a01-b056-e711-abaa-00155d701c02  1983-12-04  ...        484   False\n\n[4123 rows x 14 columns]\n"
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1658782345073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Split into train and test datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "\n"
        }
      ],
      "execution_count": 18,
      "metadata": {
        "gather": {
          "logged": 1658782345184
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Register datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%synapse\n",
        "# Register datasets into workspace\n",
        "\n",
        "from azureml.data.datapath import DataPath\n",
        "from azureml.core import Experiment, Workspace, Dataset, Datastore\n",
        "\n",
        "# Set workspace\n",
        "workspacevar = spark.read.load('wasbs://customer-churn-data@stretailprod.blob.core.windows.net/workspace.json', format='json')\n",
        "workspacevar_name = workspacevar.first()['name']\n",
        "workspacevar_id = workspacevar.first()['subscription_id']\n",
        "workspacevar_rg = workspacevar.first()['resource_group']\n",
        "ws = Workspace.get(name = workspacevar_name, subscription_id = workspacevar_id, resource_group = workspacevar_rg)\n",
        "datastore = Datastore.get_default(ws)\n",
        "dataset = Dataset.Tabular.register_pandas_dataframe(\n",
        "    df, datastore, \"CustomerChurn-new\", show_progress=True\n",
        ")\n",
        "dataset_train = Dataset.Tabular.register_pandas_dataframe(\n",
        "    train_df, datastore, \"CustomerChurn-train\", show_progress=True\n",
        ")\n",
        "dataset_test = Dataset.Tabular.register_pandas_dataframe(\n",
        "    test_df, datastore, \"CustomerChurn-test\", show_progress=True\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Validating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/7932fa6b-a695-4197-b603-418e822645bc/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\nValidating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/0a925ecd-fe12-4891-9406-2b30a4260668/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\nValidating arguments.\nArguments validated.\nSuccessfully obtained datastore reference and path.\nUploading file to managed-dataset/8bca75ef-628b-44d4-9fa7-55add8413f4b/\nSuccessfully uploaded file to datastore.\nCreating and registering a new dataset.\nSuccessfully created and registered a new dataset.\n/home/trusted-service-user/cluster-env/env/lib/python3.8/site-packages/azureml/data/dataset_factory.py:1216: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  df[column] = pd.to_datetime(df[column])\n"
        }
      ],
      "execution_count": 19,
      "metadata": {
        "gather": {
          "logged": 1658782345264
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%synapse stop\n",
        "# Stop spark pool"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Session stopped.\n"
        }
      ],
      "execution_count": 20,
      "metadata": {
        "gather": {
          "logged": 1659394805661
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model building"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and testing dataasets\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "train_df = Dataset.get_by_name(workspace = ws, name='CustomerChurn-train', version='latest')\n",
        "test_df = Dataset.get_by_name(workspace = ws, name='CustomerChurn-test', version='latest')\n"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "gather": {
          "logged": 1658864670245
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set compute target\n",
        "from azureml.core.compute import AmlCompute\n",
        "\n",
        "compute = AmlCompute(ws, \"aml-prod-compute002\")"
      ],
      "outputs": [],
      "execution_count": 22,
      "metadata": {
        "gather": {
          "logged": 1658864670730
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Configuration"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up experiment\n",
        "experiment_name = \"customerchurn-automlv3\"\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "datastore = Datastore.get_default(ws)"
      ],
      "outputs": [],
      "execution_count": 23,
      "metadata": {
        "gather": {
          "logged": 1658864671063
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializing AutoML Config\n",
        "automl_config = AutoMLConfig(task = \"classification\",\n",
        "                             training_data = train_df,\n",
        "                             test_data = test_df,\n",
        "                             compute_target = compute,\n",
        "                             n_cross_validations = 5,\n",
        "                             label_column_name = \"Churned\",\n",
        "                             primary_metric = \"AUC_weighted\",\n",
        "                             featurization = \"auto\",\n",
        "                             blocked_models=[\"LightGBM\", \"XGBoostClassifier\"],\n",
        "                             experiment_timeout_hours = 0.5,\n",
        "                             max_concurrent_iterations = 2,\n",
        "                             enable_onnx_compatible_models = False)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "gather": {
          "logged": 1658864671137
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submitting Experiment"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Running AutoML\n",
        "run = experiment.submit(automl_config)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Submitting remote run.\n"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>customerchurn-automlv3</td><td>AutoML_bc7ce871-1e44-424f-b993-681898305f9b</td><td>automl</td><td>NotStarted</td><td><a href=\"https://ml.azure.com/runs/AutoML_bc7ce871-1e44-424f-b993-681898305f9b?wsid=/subscriptions/506e86fc-853c-4557-a6e5-ad72114efd2b/resourcegroups/rg-aidreamdemo/workspaces/mlw-aidemo-prod&amp;tid=f94768c8-8714-4abe-8e2d-37a64b18216a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "gather": {
          "logged": 1658864676219
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing best model\n",
        "run.wait_for_completion()\n",
        "\n",
        "# Get best model from automl run\n",
        "best_run, non_onnx_model = run.get_output()\n",
        "\n",
        "artifact_path = experiment_name + \"_artifact\""
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1658784297034
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Register best model in MLFlow"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "\n",
        "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
        "mlflow.set_experiment(experiment_name)\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "    # Save the model to the outputs directory for capture\n",
        "    mlflow.sklearn.log_model(non_onnx_model, artifact_path)\n",
        "\n",
        "    # Register the model to AML model registry\n",
        "    mlflow.register_model(\"runs:/\" + run.info.run_id + \"/\" + artifact_path, \"customerchurn-automlv3-Best\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1658782345910
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}